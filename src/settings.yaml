backend:
  app:
    host: "0.0.0.0"   # Host address (use 0.0.0.0 for LAN access; or 127.0.0.1 for host machine access only) // Default: 0.0.0.0
    port: 11405       # Port number for the web server (can be any unassigned port) // Default: 11405
    protocol: https   # Use HTTP/HTTPS (set "http", "https", or "both". For https, cert.pem and key.pem must be present in the same directory as app.py!) // Default: http
  logging:
    level: "ERROR"    # Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) // Default: ERROR
  urls:
    ollama_webhook: http://homeassistant.local:8123/api/webhook/ollama_chat    # Webhook URL for your Ollama endpoint, as configured in HAOS automations.
    whisper_webhook: http://homeassistant.local:8123/api/webhook/whisper       # Webhook URL for Whisper endpoint.

frontend:
  show-sent-prompts: true    # After sending a text prompt, should it be displayed? // Default: true
  enable-text-repeat: true   # Enable the button to re-paste your previous text prompt into the input text field // Default: true
  enable-mouth-scaling: true  # Scale the mouth movement of the Live2D model according to the syllables being pronounced. Disable if too resource intensive on older browsers/devices. // Default: true
  timeout: 180               # How long should the user wait for a response from the pipeline before timing out (in seconds?) // Default: 180
  model_path: /live2d_models/lafeiii_3/lafeiii_3.model3.json       # Specify the path of which Live2D model to use // Default: /live2d_models/test/test.model3.json
  scale: 0.2                 # Specify the initial scaling of the Live2D model // Default: 0.2
